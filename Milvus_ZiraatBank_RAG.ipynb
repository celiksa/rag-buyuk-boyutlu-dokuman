{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "49c8f1a1",
   "metadata": {},
   "source": [
    "### Importing Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f1a93f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install sentence-transformers==2.2.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c90bfb0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import pdfplumber\n",
    "from configparser import ConfigParser\n",
    "from pymilvus import connections, Collection, utility\n",
    "from langchain.embeddings import HuggingFaceInstructEmbeddings\n",
    "from langchain.vectorstores import Milvus\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from sentence_transformers import CrossEncoder\n",
    "from ibm_watson_machine_learning.foundation_models import Model\n",
    "from ibm_watson_machine_learning.metanames import GenTextParamsMetaNames as GenParams\n",
    "from prompt import prompt_generator\n",
    "from sentence_transformers import SentenceTransformer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f321db0",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install ibm_watson_machine_learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2dcb95df",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yunusemreemik/Documents/PythonApps/rag-buyuk-boyutlu-dokuman/api-env/lib/python3.12/site-packages/InstructorEmbedding/instructor.py:7: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import trange\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load INSTRUCTOR_Transformer\n",
      "max_seq_length  512\n"
     ]
    }
   ],
   "source": [
    "from langchain.embeddings import HuggingFaceInstructEmbeddings\n",
    "\n",
    "# Initialize embeddings\n",
    "embeddings = HuggingFaceInstructEmbeddings(\n",
    "    model_name=\"sentence-transformers/paraphrase-multilingual-mpnet-base-v2\",\n",
    "    model_kwargs={\"device\": \"cpu\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b622f69d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d626d49d",
   "metadata": {},
   "source": [
    "### RAG- using Milvus Vector DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d3ec455",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ZiraatBankQA:\n",
    "    def __init__(self, config_path):\n",
    "        self.config = self.load_config(config_path)\n",
    "       \n",
    "        self.creds ,self.project_id = self.get_wml_creds()\n",
    "        self.model_id = self.config['DEFAULT']['ModelID']\n",
    "        self.embeddings = HuggingFaceInstructEmbeddings(model_name=self.config['DEFAULT']['EmbeddingsModel'])\n",
    "#         self.embeddings = SentenceTransformer('sentence-transformers/distiluse-base-multilingual-cased-v2')\n",
    "\n",
    "        self.text_splitter = RecursiveCharacterTextSplitter(\n",
    "            separators=['\\n\\n', '\\n', '.', ' '],\n",
    "            chunk_size=768,\n",
    "            chunk_overlap=100,\n",
    "            length_function=len\n",
    "        )\n",
    "        # self.collection_name = self.config['Milvus']['CollectionName']\n",
    "        self.host = self.config['Milvus']['Host']\n",
    "        self.port = self.config['Milvus']['Port']\n",
    "        self.user = self.config['Milvus']['User']\n",
    "        self.password = self.config['Milvus']['Password']\n",
    "        self.server_pem_path = self.config['Milvus']['ServerPemPath']\n",
    "        self.server_name = self.config['Milvus']['ServerName']\n",
    "\n",
    "    def load_config(self, config_path):\n",
    "        config = ConfigParser()\n",
    "        config.read(config_path)\n",
    "        return config\n",
    "\n",
    "    def get_wml_creds(self):\n",
    "        api_key = \"1xB9UAYxbDnLuEF1INyZn3vAF9KkvvKnTzxBq0-FUuiR\"\n",
    "        ibm_cloud_url = \"https://us-south.ml.cloud.ibm.com\"\n",
    "        project_id = \"86cc43a6-c2f0-4e3e-a6e9-426ac8cf8f7b\"\n",
    "        if api_key is None or ibm_cloud_url is None or project_id is None:\n",
    "            print(\"Ensure you copied the .env file that you created earlier into the same directory as this script\")\n",
    "        else:\n",
    "            creds = {\n",
    "                \"url\": ibm_cloud_url,\n",
    "                \"apikey\": api_key \n",
    "            }\n",
    "        return creds ,project_id\n",
    "\n",
    "    def send_to_watsonxai(self, prompt):\n",
    "        params = {\n",
    "            GenParams.DECODING_METHOD: \"greedy\",\n",
    "            GenParams.MIN_NEW_TOKENS: 1,\n",
    "            GenParams.MAX_NEW_TOKENS: 200,\n",
    "            GenParams.TEMPERATURE: 0,\n",
    "        }\n",
    "        model = Model(model_id=self.model_id, params=params, credentials=self.creds, project_id=self.project_id)\n",
    "        response = model.generate_text(prompt)\n",
    "        return response\n",
    "\n",
    "    def load_documents(self, folder_path):\n",
    "        text_chunks = []\n",
    "        files = glob.glob(os.path.join(folder_path, '*.pdf'))\n",
    "\n",
    "        for file in tqdm(files):\n",
    "            with pdfplumber.open(file) as pdf:\n",
    "                data = ''.join([page.extract_text() for page in pdf.pages])\n",
    "\n",
    "            created_text_chunks = self.text_splitter.create_documents([data])\n",
    "            for chunks in created_text_chunks:\n",
    "                chunks.metadata['file'] = file\n",
    "                text_chunks.append(chunks)\n",
    "\n",
    "        return text_chunks\n",
    "\n",
    "    def create_vector_store(self, text_chunks,connection_name):\n",
    "        connections.connect(\n",
    "            \"default\", \n",
    "            host=self.host, \n",
    "            port=self.port, \n",
    "            secure=True, \n",
    "            server_pem_path=self.server_pem_path, \n",
    "            server_name=self.server_name, \n",
    "            user=self.user, \n",
    "            password=self.password\n",
    "        )\n",
    "\n",
    "        if utility.has_collection(connection_name):\n",
    "            utility.drop_collection(connection_name)\n",
    "\n",
    "        vector_db = Milvus.from_documents(\n",
    "            text_chunks,\n",
    "            self.embeddings,\n",
    "            connection_args={\n",
    "                \"host\": self.host,\n",
    "                \"port\": self.port,\n",
    "                \"secure\": True,\n",
    "                \"server_pem_path\": self.server_pem_path,\n",
    "                \"server_name\": self.server_name,\n",
    "                \"user\": self.user,\n",
    "                \"password\": self.password\n",
    "            },\n",
    "            collection_name=connection_name\n",
    "        )\n",
    "\n",
    "        collection = Collection(connection_name)\n",
    "        collection.load()\n",
    "        return vector_db\n",
    "\n",
    "    def perform_qa(self, df, query):\n",
    "        context = \"\\n\\n\".join(df['paragraph'])\n",
    "        prompt = prompt_generator(context, query)\n",
    "        response = self.send_to_watsonxai(prompt)\n",
    "        return response, context\n",
    "\n",
    "    def create_model(self, model_name):\n",
    "        model = CrossEncoder(model_name, max_length=512)\n",
    "        return model\n",
    "    \n",
    "    def main(self, query, vector_db, model):\n",
    "        docs = vector_db.similarity_search_with_score(query, k=12, ef=7)\n",
    "        \n",
    "        _docs = pd.DataFrame(\n",
    "            [(query, doc[0].page_content, doc[0].metadata.get('file'), doc[1]) for doc in docs],\n",
    "            columns=['query', 'paragraph', 'document', 'relevent_score']\n",
    "        )\n",
    "        scores = model.predict(_docs[['query', 'paragraph']].to_numpy())\n",
    "        _docs['score'] = scores\n",
    "        df = _docs[:12]\n",
    "\n",
    "        response, context = self.perform_qa(df, query)\n",
    "        return response, context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b28d58a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d1196876",
   "metadata": {},
   "source": [
    "### LLAMA3 Inference Q1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30c90e45",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    query = \"M.Ö. 3000’lerden itibaren Smyrna’nın yerleşim yeri neresi olmuştur?\"\n",
    "    folder_path = 'Large'\n",
    "    config_path = 'config.ini'\n",
    "    ziraat_bank_qa = ZiraatBankQA(config_path)\n",
    "    text_chunks = ziraat_bank_qa.load_documents(folder_path)\n",
    "    vector_db = ziraat_bank_qa.create_vector_store(text_chunks)\n",
    "    model = ziraat_bank_qa.create_model('emrecan/bert-base-turkish-cased-mean-nli-stsb-tr')\n",
    "    response, context = ziraat_bank_qa.main(query, vector_db, model)\n",
    "    print(response)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c52a6e5",
   "metadata": {},
   "source": [
    "### LLAMA3 Inference Q2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dab2f2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"Tekâlîf-i fevkalâde vergisi nedir? Hangi kısımlardan oluşur? \"\n",
    "response, context = ziraat_bank_qa.main(query, vector_db)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9de7b67",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"11. yüzyılda Smyrna bölgesinde ne olmuştur?\"\n",
    "response, context = ziraat_bank_qa.main(query, folder_path)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "761e4a68",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"Smyrna ilk kuruluşu nerede ve ne zaman olmuştur? \"\n",
    "response, context = ziraat_bank_qa.main(query, folder_path)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee5317e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"Arzava ve Assuva'nın Smyrna açısından önemi nedir? \"\n",
    "response, context = ziraat_bank_qa.main(query, folder_path)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c987b561",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"Charles Texier tarafından Smyrna konusunda hangi çalışmalar yapılmıştır?\"\n",
    "response, context = ziraat_bank_qa.main(query, folder_path)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ef7e97c",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"Aiollerin Smyrna çevresinde kurduğu federasyonda hangi kentler bulunmaktadır?\"\n",
    "response, context = ziraat_bank_qa.main(query, folder_path)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6f1d457",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"İzmir iktisat kongresinde tüccar grubu tarafından belirlenen başlıca ilkeler nelerdir?\"\n",
    "response, context = ziraat_bank_qa.main(query, folder_path)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32b955e1",
   "metadata": {},
   "source": [
    "### Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c401d556",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Specify the path to your Excel file\n",
    "excel_file_path = 'Validation_set/validation_set_yns.xlsx'\n",
    "\n",
    "# Read the Excel file into a DataFrame using the openpyxl engine\n",
    "df = pd.read_excel(excel_file_path, engine='openpyxl')\n",
    "\n",
    "\n",
    "responses = []\n",
    "\n",
    "for query in df['Soru']:\n",
    "    response, context = ziraat_bank_qa.main(query, folder_path)\n",
    "    responses.append(response)\n",
    "    \n",
    "# Add the questions & responses to the DataFrame\n",
    "df['response'] = responses\n",
    "\n",
    "#save the model response\n",
    "\n",
    "# fixed encoding issue.\n",
    "df.to_excel('output.xlsx', engine='openpyxl', encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a433436b",
   "metadata": {},
   "source": [
    "### "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
